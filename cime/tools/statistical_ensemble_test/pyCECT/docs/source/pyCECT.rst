
pyCECT test
==============================================


CESM-ECT suite contains multiple tests is to compare the results of a set of new (modified)
CESM simulations against the accepted ensemble. An overall pass or fail is designated.
Current functionality in the CESM-ECT suite includes:

*Atmosphere component (CAM):*

  * CAM-ECT: examines yearly-average files from CAM 
  * UF-CAM-ECT: examine history files from CAM 

    Both CAM-ECT and UF-CAM-ECT require a summary file generated by 
    pyEnsSum.py.  UF-CAM-ECT uses simulations of nine time-steps in length, while
    CAM-ECT uses yearly averages.  The faster UF-CAM-ECT is always
    suggested to start with. (The CAM-ECT is typically only used in the case of an unexpected
    UF-CAM-ECT fail.) Three simulation runs from the new test environment are
    recommended for both of these tests. More information is available in:

    Daniel J. Milroy, Allison H. Baker, Dorit M. Hammerling, and
    Elizabeth R. Jessup, “Nine time steps: ultra-fast statistical
    consistency testing of the Community Earth System Model (pyCECT
    v3.0)”, Geoscientific Model Development, 11, pp. 697-711, 2018.

    https://gmd.copernicus.org/articles/11/697/2018/



*Ocean Component (POP):*

 * POP-ECT: examines monthly-average files from POP 


   POP-ECT requires  a summary file generated by pyEnsSumPop.py and uses
   monthly output, typically from a single year. One simulation run from
   the new test environment is needed.  More information is available in:

   A.H. Baker, Y. Hu, D.M. Hammerling, Y. Tseng, X. Hu, X. Huang,
   F.O. Bryan, and G. Yang, “Evaluating Statistical Consistency in the
   Ocean Model Component of the Community Earth System Model
   (pyCECT v2.0).” Geoscientific Model Development, 9, pp. 2391-2406, 2016.

   https://gmd.copernicus.org/articles/9/2391/2016/



To use pyCECT:
---------------
*Note: compatible with python 3*

1. On NCAR's Cheyenne machine:

   ``module load python``

   ``ncar_pylib``

   ``qsub test_pyEnsSum.sh``


2. Otherwise you need these packages:

         * numpy
	 * scipy
	 * future
	 * configparser
	 * sys
	 * getopt
	 * os
	 * netCDF4
	 * time
	 * re
	 * json
	 * random
	 * asaptools
	 * fnmatch
	 * glob
	 * itertools
	 * datetime



3. To see all options (and defaults):

   ``python pyCECT.py -h``


Notes and examples:
--------------------------------------------

1. Options for all CESM-ECT approaches:

   Required:

   * To specify the summary file generated by pyEnsSum.py

     ``--sumfile  ens.summary.nc``

   * To specifying the directory path that contains the run(s) to be evaluated:

     ``--indir  /glade/u/tdd/asap/verification/cesm1_3_beta11/mira``

   Optional:

  * For verbose information:

   ``--verbose``

2. CAM-ECT and UF-CAM-ECT specific options (and summary file generated by pyEnsSum.py)

   * Note that CAM-ECT is the default test.

   * The parameters setting the pass/fail criteria are all set by 
     default (ie. sigMul, minPCFail, minRunFail, numRunFile, and nPC).   

   * If the specified indir contains more files than the number specified by 

     ``--numRunFile <num>``

     (default= 3), then <num> files will be chosen at random 
     from that directory.

   * The Ensemble Exhaustive Test (EET) is specified by

     ``--eet <num>``

     This tool computes the failure rate of <num> tests taken  <numRunFile> at a time.
     Therefore, when specifying ``--eet <num>``, <num> must be greater than or equal to
     <numRunFile>. 

   * To enable printing of extra variable information:

    ``--printVars``

    * By default, CAM-ECT looks at annual averages which is indictated by 

     ``--tslice 1``  

     (For monthly files, use ``--tslice 0``.  Note that this 
     should correspond to what has been collected in the summary file.)

   * To enable printing out sum of standardized mean of all variables and associated box plots
     (requries the Python seaborn package):

     ``--printStdMean``


   * To save a netcdf file with scores and std global means from the test runs (savefile.nc):

      ``--saveResults``

   *   *Example:*
    
    ``python pyCECT.py --sumfile /glade/p/cisl/asap/pycect_sample_data/cam_c1.2.2.1/summary_files/uf.ens.c1.2.2.1_fc5.ne30.nc --indir /glade/p/cisl/asap/pycect_sample_data/cam_c1.2.2.1/uf_cam_test_files --tslice 1``

  *  *Example using EET* (note that EET takes longer to run - especially for a large number of tests):

   ``python pyCECT.py --sumfile /glade/p/cisl/asap/pycect_sample_data/cam_c1.2.2.1/summary_files/uf.ens.c1.2.2.1_fc5.ne30.nc --indir /glade/p/cisl/asap/pycect_sample_data/cam_c1.2.2.1/uf_cam_test_files --tslice 1 --eet 10``


3. POP-ECT specific options (and summary file generated by pyEnsSumPop.py)
      
   * To use POP-ECT, you MUST add the following to enable this test 
     (which disables UF-CAM-ECT and CAM-ECT):
      
   ``--popens`` 

   * Be sure to use a POP-ECT summary file:
           
   ``--sumfile /glade/p/cisl/asap//pycect_sample_data/pop_c2.0.b10/summary_files/pop.cesm2.0.b10.nc`` 
      
   * Directory path that contains the run(s) to be evaluated.
	    
    ``--indir /glade/p/cisl/asap//pycect_sample_data/pop_c2.0.b10/pop_test_files/C96`` 

   * The above directory may contain many POP history files that following the standard 
      CESM-POP naming convention. To specific which file or files you wish to test, you 
      simply specifying the test case file prefix (like a wildcard expansion). 

      * To compare against all months in year 2 from the input directory above:

       ``--input_glob C96.pop.000.pop.h.0002``
           
      * To compare only against month 12 in year 1:

       ``--input_glob C96.pop.000.pop.h.0001-12``

      * (Note: if input_glob is not specified, all files in --indir will be compared)

      * (Note: the recommendation is to just compare year 1, month 12)


    * Be sure to specify the json file that includes the variables which will be run the test on:

     ``--jsonfile pop_ensemble.json``

   * The parameters setting the pass/fail criteria are all set by 
     default (ie. pop_tol, pop_threshold) but may be modified:

     * Specifying test tolerance (the minimum Z-score
       threshold):

      ``--pop_tol 3.0``

     * Specifying pop threshold (fraction of points that must satisfy the Z-score tolerance):

      ``--pop_threshold 0.9``

    
  * *Example:*
         
    ``python pyCECT.py --popens --sumfile /glade/p/cisl/asap//pycect_sample_data/pop_c2.0.b10/summary_files/pop.cesm2.0.b10.nc --indir /glade/p/cisl/asap//pycect_sample_data/pop_c2.0.b10/pop_test_files/C96 --jsonfile pop_ensemble.json --input_glob C96.pop.000.pop.h.0001-12``
